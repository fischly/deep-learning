{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic - Machine Learning from Disaster\n",
    "\n",
    "\n",
    "Kaggle link: https://www.kaggle.com/c/titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the needed library and init Weights and Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "torch.manual_seed(0)\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:16vne809) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1268f887b8234d03a640439a8eb966a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.026 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.035819…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>correct%</td><td>▁▆███▇▇▆▆▆▅▅▅▆▅▆▅▆▅▆▇▇▆▆▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>training_loss</td><td>█▄▃▂▂▂▂▂▂▂▂▁▂▁▂▂▁▂▁▂▂▂▁▁▂▂▁▂▁▂▂▂▁▁▁▂▁▁▁▂</td></tr><tr><td>validation_loss</td><td>█▃▂▂▂▄▁▃▂▂▄▄▂▂▃▁▂▃▂▁▃▂▂▂▁▂▂▄▂▄▁▂▁▃▂▃▁▄▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>correct%</td><td>0.82836</td></tr><tr><td>epoch</td><td>399</td></tr><tr><td>training_loss</td><td>8.20933</td></tr><tr><td>validation_loss</td><td>3.57178</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">autumn-bird-9</strong>: <a href=\"https://wandb.ai/fischly/titanic/runs/16vne809\" target=\"_blank\">https://wandb.ai/fischly/titanic/runs/16vne809</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221102_210519-16vne809\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:16vne809). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af60719eadc04893b3798ebd78c4876d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Binaries\\WPy64-31050\\notebooks\\pr-dl\\Ex3\\wandb\\run-20221102_210624-44xgyq8k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/fischly/titanic/runs/44xgyq8k\" target=\"_blank\">vibrant-bird-10</a></strong> to <a href=\"https://wandb.ai/fischly/titanic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/fischly/titanic/runs/44xgyq8k?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1b3407a2bf0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 400\n",
    "lr = 5e-3\n",
    "batch_size = 32\n",
    "momentum = 0\n",
    "\n",
    "wandb.init(project='titanic', config={\n",
    "    'num-epochs': num_epochs,\n",
    "    'learning-rate': lr,\n",
    "    'batch-size': batch_size,\n",
    "    'momentum': momentum\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to read the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_training_data = pd.read_csv('data/train.csv')\n",
    "titanic_test_data = pd.read_csv('data/test.csv')\n",
    "titanic_training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe needs to be cleaned, knowing if some informations are unknown can be very important to determine if someone survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Age     SibSp     Parch      Fare  ageNan  cabinNan  embarkedNan  \\\n",
      "0  -5.300051e-01  0.432550 -0.473408  1.981001   False      True        False   \n",
      "1   5.714304e-01  0.432550 -0.473408  4.266662   False     False        False   \n",
      "2  -2.546462e-01 -0.474279 -0.473408  2.070022   False      True        False   \n",
      "3   3.649113e-01  0.432550 -0.473408  3.972177   False     False        False   \n",
      "4   3.649113e-01 -0.474279 -0.473408  2.085672   False      True        False   \n",
      "5   2.003921e-16 -0.474279 -0.473408  2.135148    True      True        False   \n",
      "6   1.672866e+00 -0.474279 -0.473408  3.948596   False     False        False   \n",
      "7  -1.906799e+00  2.246209  0.767199  3.048088   False      True        False   \n",
      "8  -1.858065e-01 -0.474279  2.007806  2.409941   False      True        False   \n",
      "9  -1.080723e+00  0.432550 -0.473408  3.403555   False      True        False   \n",
      "10 -1.769120e+00  0.432550  0.767199  2.815409   False     False        False   \n",
      "11  1.948225e+00 -0.474279 -0.473408  3.279030   False     False        False   \n",
      "12 -6.676845e-01 -0.474279 -0.473408  2.085672   False      True        False   \n",
      "13  6.402701e-01  0.432550  5.729626  3.442819   False      True        False   \n",
      "14 -1.080723e+00 -0.474279 -0.473408  2.061048   False      True        False   \n",
      "15  1.741706e+00 -0.474279 -0.473408  2.772589   False      True        False   \n",
      "16 -1.906799e+00  3.153038  0.767199  3.371597   False      True        False   \n",
      "17  2.003921e-16 -0.474279 -0.473408  2.564949    True      True        False   \n",
      "18  8.955238e-02  0.432550 -0.473408  2.890372   False      True        False   \n",
      "19  2.003921e-16 -0.474279 -0.473408  1.977547    True      True        False   \n",
      "20  3.649113e-01 -0.474279 -0.473408  3.258097   False      True        False   \n",
      "21  2.960715e-01 -0.474279 -0.473408  2.564949   False     False        False   \n",
      "22 -1.011883e+00 -0.474279 -0.473408  2.083085   False      True        False   \n",
      "23 -1.169668e-01 -0.474279 -0.473408  3.569533   False     False        False   \n",
      "24 -1.493761e+00  2.246209  0.767199  3.048088   False      True        False   \n",
      "25  5.714304e-01  0.432550  5.729626  3.446410   False      True        False   \n",
      "26  2.003921e-16 -0.474279 -0.473408  1.977547    True      True        False   \n",
      "27 -7.365243e-01  2.246209  2.007806  5.572154   False     False        False   \n",
      "28  2.003921e-16 -0.474279 -0.473408  2.064226    True      True        False   \n",
      "29  2.003921e-16 -0.474279 -0.473408  2.066331    True      True        False   \n",
      "\n",
      "    isChild  isSenior   famSize  ...  pclass__1  pclass__2  pclass__3  \\\n",
      "0     False     False  0.059127  ...      False      False       True   \n",
      "1     False     False  0.059127  ...       True      False      False   \n",
      "2     False     False -0.560660  ...      False      False       True   \n",
      "3     False     False  0.059127  ...       True      False      False   \n",
      "4     False     False -0.560660  ...      False      False       True   \n",
      "5     False     False -0.560660  ...      False      False       True   \n",
      "6     False     False -0.560660  ...       True      False      False   \n",
      "7      True     False  1.918486  ...      False      False       True   \n",
      "8     False     False  0.678913  ...      False      False       True   \n",
      "9      True     False  0.059127  ...      False       True      False   \n",
      "10     True     False  0.678913  ...      False      False       True   \n",
      "11    False     False -0.560660  ...       True      False      False   \n",
      "12    False     False -0.560660  ...      False      False       True   \n",
      "13    False     False  3.158060  ...      False      False       True   \n",
      "14     True     False -0.560660  ...      False      False       True   \n",
      "15    False     False -0.560660  ...      False       True      False   \n",
      "16     True     False  2.538273  ...      False      False       True   \n",
      "17    False     False -0.560660  ...      False       True      False   \n",
      "18    False     False  0.059127  ...      False      False       True   \n",
      "19    False     False -0.560660  ...      False      False       True   \n",
      "20    False     False -0.560660  ...      False       True      False   \n",
      "21    False     False -0.560660  ...      False       True      False   \n",
      "22     True     False -0.560660  ...      False      False       True   \n",
      "23    False     False -0.560660  ...       True      False      False   \n",
      "24     True     False  1.918486  ...      False      False       True   \n",
      "25    False     False  3.158060  ...      False      False       True   \n",
      "26    False     False -0.560660  ...      False      False       True   \n",
      "27    False     False  2.538273  ...       True      False      False   \n",
      "28    False     False -0.560660  ...      False      False       True   \n",
      "29    False     False -0.560660  ...      False      False       True   \n",
      "\n",
      "    embarked__C  embarked__Q  embarked__S  title__0  title__1  title__2  \\\n",
      "0         False        False         True         0         0         1   \n",
      "1          True        False        False         0         1         0   \n",
      "2         False        False         True         0         1         0   \n",
      "3         False        False         True         0         1         0   \n",
      "4         False        False         True         0         0         1   \n",
      "5         False         True        False         0         0         1   \n",
      "6         False        False         True         0         0         1   \n",
      "7         False        False         True         1         0         0   \n",
      "8         False        False         True         0         1         0   \n",
      "9          True        False        False         0         1         0   \n",
      "10        False        False         True         0         1         0   \n",
      "11        False        False         True         0         1         0   \n",
      "12        False        False         True         0         0         1   \n",
      "13        False        False         True         0         0         1   \n",
      "14        False        False         True         0         1         0   \n",
      "15        False        False         True         0         1         0   \n",
      "16        False         True        False         1         0         0   \n",
      "17        False        False         True         0         0         1   \n",
      "18        False        False         True         0         1         0   \n",
      "19         True        False        False         0         1         0   \n",
      "20        False        False         True         0         0         1   \n",
      "21        False        False         True         0         0         1   \n",
      "22        False         True        False         0         1         0   \n",
      "23        False        False         True         0         0         1   \n",
      "24        False        False         True         0         1         0   \n",
      "25        False        False         True         0         1         0   \n",
      "26         True        False        False         0         0         1   \n",
      "27        False        False         True         0         0         1   \n",
      "28        False         True        False         0         1         0   \n",
      "29        False        False         True         0         0         1   \n",
      "\n",
      "    title__3  \n",
      "0          0  \n",
      "1          0  \n",
      "2          0  \n",
      "3          0  \n",
      "4          0  \n",
      "5          0  \n",
      "6          0  \n",
      "7          0  \n",
      "8          0  \n",
      "9          0  \n",
      "10         0  \n",
      "11         0  \n",
      "12         0  \n",
      "13         0  \n",
      "14         0  \n",
      "15         0  \n",
      "16         0  \n",
      "17         0  \n",
      "18         0  \n",
      "19         0  \n",
      "20         0  \n",
      "21         0  \n",
      "22         0  \n",
      "23         0  \n",
      "24         0  \n",
      "25         0  \n",
      "26         0  \n",
      "27         0  \n",
      "28         0  \n",
      "29         0  \n",
      "\n",
      "[30 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "def clean_titanic(df, train=True):\n",
    "    # store whether some fields are not given as new feature\n",
    "    df['ageNan'] = df['Age'].apply(lambda x: pd.isna(x)).astype(bool)\n",
    "    df['cabinNan'] = df['Cabin'].apply(lambda x: pd.isna(x)).astype(bool)\n",
    "    df['embarkedNan'] = df['Embarked'].apply(lambda x: pd.isna(x)).astype(bool)\n",
    "\n",
    "    # create a feature that says whether a person is a child (age < 16) or a senor (age > 60)\n",
    "    df['isChild'] = df['Age'].apply(lambda x: x < 16).astype(bool)\n",
    "    df['isSenior'] = df['Age'].apply(lambda x: x > 60).astype(bool)\n",
    "    \n",
    "    # extract title (taken from: https://www.kaggle.com/code/yassineghouzam/titanic-top-4-with-ensemble-modeling)\n",
    "    df['title'] = [i.split(',')[1].split('.')[0].strip() for i in df['Name']]\n",
    "    df['title'] = df['title'].replace(['Lady', 'the Countess','Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "    df['title'] = df['title'].map({'Master': 0, 'Miss': 1, 'Ms': 1 , 'Mme': 1, 'Mlle': 1, 'Mrs': 1, 'Mr': 2, 'Rare': 3})\n",
    "    \n",
    "    # family size (taken from: https://www.kaggle.com/code/yassineghouzam/titanic-top-4-with-ensemble-modeling)\n",
    "    df['famSize'] = df['SibSp'] + df['Parch'] + 1\n",
    "    df['famSingle'] = df['famSize'].map(lambda x: 1 if x == 1 else 0)\n",
    "    df['famSmall'] = df['famSize'].map(lambda x: 1 if  x == 2  else 0)\n",
    "    df['famMed'] = df['famSize'].map(lambda s: 1 if 3 <= s <= 4 else 0)\n",
    "    df['famLarge'] = df['famSize'].map(lambda s: 1 if s >= 5 else 0)\n",
    "    \n",
    "    # one-hot-encoding of categorical fields (sex, class and embarked)\n",
    "    df = pd.concat([\n",
    "        df,\n",
    "        pd.get_dummies(df['Sex'], dtype='bool', prefix='sex_'),\n",
    "        pd.get_dummies(df['Pclass'], dtype='bool', prefix='pclass_'),\n",
    "        pd.get_dummies(df['Embarked'], dtype='bool', prefix='embarked_'),\n",
    "        pd.get_dummies(df['title'], prefix='title_')\n",
    "    ], axis=1)\n",
    "    df = df.drop(['PassengerId', 'Name', 'Ticket', 'Sex', 'Pclass', 'Embarked', 'Cabin', 'title'], axis=1)\n",
    "\n",
    "    if train:\n",
    "        df = df.drop(['Survived'], axis=1)\n",
    "\n",
    "    # normalize all numerical features (like Age, SibSp, Parch and Fare)\n",
    "    df['Fare'] = df['Fare'].map(lambda i: np.log(i) if i > 0 else 0)\n",
    "    \n",
    "    numeric_features = ['Age', 'SibSp', 'Parch', 'famSize']   #df.dtypes[(df.dtypes != 'object') & (df.dtypes != 'bool')].index\n",
    "    df[numeric_features] = df[numeric_features].apply(lambda x: (x - x.mean()) / (x.std()))\n",
    "\n",
    "    # fill rows where Age/Fare is not given with the mean of all persons' ages/fares\n",
    "    df['Age'] = df['Age'].fillna(df['Age'].mean())\n",
    "    df['Fare'] = df['Fare'].fillna(df['Fare'].median())\n",
    "    \n",
    "\n",
    "    return df\n",
    "\n",
    "targets = torch.tensor(titanic_training_data[\"Survived\"].values, dtype=torch.float32)\n",
    "training_data = clean_titanic(titanic_training_data)\n",
    "print(training_data.head(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then transform the data from numpy (pandas representation) into torch's `Tensor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5300,  0.4326, -0.4734,  1.9810,  0.0000,  1.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0591,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,\n",
       "          0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,\n",
       "          1.0000,  0.0000],\n",
       "        [ 0.5714,  0.4326, -0.4734,  4.2667,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0591,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,\n",
       "          1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,\n",
       "          0.0000,  0.0000],\n",
       "        [-0.2546, -0.4743, -0.4734,  2.0700,  0.0000,  1.0000,  0.0000,  0.0000,\n",
       "          0.0000, -0.5607,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,\n",
       "          0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  1.0000,\n",
       "          0.0000,  0.0000],\n",
       "        [ 0.3649,  0.4326, -0.4734,  3.9722,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0591,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,\n",
       "          1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  1.0000,\n",
       "          0.0000,  0.0000],\n",
       "        [ 0.3649, -0.4743, -0.4734,  2.0857,  0.0000,  1.0000,  0.0000,  0.0000,\n",
       "          0.0000, -0.5607,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,\n",
       "          0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,\n",
       "          1.0000,  0.0000]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_tensor = torch.tensor(training_data.astype('float').values, dtype=torch.float32)\n",
    "training_tensor[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `TensorDataset` to get tuple of data and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = torch.utils.data.TensorDataset(training_tensor, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then split between the training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_size = int(0.7 * len(dataset))\n",
    "validation_size = len(dataset) - training_size\n",
    "\n",
    "# random_split creates subsets\n",
    "train, val = torch.utils.data.random_split(dataset, [training_size, validation_size], generator=torch.Generator().manual_seed(0))\n",
    "\n",
    "data_loader_train = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "data_loader_val = torch.utils.data.DataLoader(val, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layer initialization using Xavier Uniform on the weight and a constant 0 value on the bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#TODO Xavier Uniform to the weight and set the bias to 0\n",
    "def init_first_layer(m):\n",
    "    torch.nn.init.xavier_normal_(m.weight)\n",
    "    torch.nn.init.constant_(m.bias, 0)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the LinearModel with one Linear layer and Sigmoid applied to the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LinearModel(nn.Module):\n",
    "    #TODO One linear layer and Sigmoid to the ouput\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.linear = init_first_layer(nn.Linear(in_dim, out_dim))\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        pred = self.linear(x)\n",
    "        return self.sigmoid(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the network (call it `net`, it would makes things easier later), the loss, the optimizer and write the training loop\n",
    "\n",
    "Don't forget to check the validation loss and save your model at the end of each epoch!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='epoch', ylabel='correct'>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "net = LinearModel(training_tensor.shape[1], 1)\n",
    "\n",
    "# use binary cross entropy loss for binary classification\n",
    "criterion = nn.BCELoss()\n",
    "# stochastic gradient decent optimizer\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "wandb.watch(net, log='all', criterion=criterion, log_freq=8,  log_graph=(True))\n",
    "\n",
    "\n",
    "epoch_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    training_loss = 0\n",
    "\n",
    "    # iterate over batches\n",
    "    for (X, y) in data_loader_train:\n",
    "        y_hat = net(X)\n",
    "        loss = criterion(y_hat.squeeze(), y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        training_loss += loss.item()\n",
    "\n",
    "    # VALIDATION LOOP\n",
    "    counter = 0\n",
    "    correct = 0\n",
    "    validation_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (X, y) in data_loader_val:\n",
    "            y_hat = net(X)\n",
    "            loss = criterion(y_hat.squeeze(), y)\n",
    "            validation_loss += loss.item()\n",
    "\n",
    "            survived = y == 1.0\n",
    "            survived_hat = y_hat.squeeze() > 0.5\n",
    "\n",
    "            counter += len(y)\n",
    "            correct += (survived == survived_hat).sum().item()\n",
    "\n",
    "    epoch_losses.append({'epoch': epoch, 'loss': validation_loss, 'correct': correct / counter})\n",
    "    \n",
    "    wandb.log({'epoch': epoch, 'training_loss': training_loss, 'validation_loss': validation_loss, 'correct%': correct / counter})\n",
    "\n",
    "    # SAVE THE MODEL\n",
    "    torch.save(net.state_dict(), f'model/model-e{str(epoch).zfill(4)}.pt')\n",
    "    \n",
    "sns.lineplot(data=pd.DataFrame(epoch_losses), x='epoch', y='correct')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This loop computes the prediction on the test dataset and create a submission file\n",
    "\n",
    "You then just have to click the submit button to get your score, lucky you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titanic_test_data_cleaned = clean_titanic(titanic_test_data, train=False)\n",
    "titanic_data_tensor = torch.tensor(titanic_test_data_cleaned.astype('float').values, dtype=torch.float32)\n",
    "\n",
    "with torch.no_grad():\n",
    "    net.eval() # enable evaluation mode\n",
    "    test_pred = torch.LongTensor()\n",
    "\n",
    "    for i, data in enumerate(titanic_data_tensor):\n",
    "        output = net(data)\n",
    "        predicted = torch.ge(output, 0.5)\n",
    "        test_pred = torch.cat((test_pred, predicted), dim=0)\n",
    "\n",
    "    out_df = pd.DataFrame(np.c_[titanic_test_data['PassengerId'].values, test_pred.numpy()], columns=['PassengerId', 'Survived'])\n",
    "    out_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
